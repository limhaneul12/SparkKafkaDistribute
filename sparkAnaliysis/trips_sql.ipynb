{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from typing import Generator, List\n",
    "import pandas as pd \n",
    "import os \n",
    "\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"year-taxi\").getOrCreate()\n",
    "\n",
    "# directory: Generator[str, None, None] = (f\"{os.getcwd()}/data/{i}\" for i in range(1, len(os.listdir(f\"{os.getcwd()}/data\"))))\n",
    "# filename: List[str] = [f\"{p}/{data}\" for p in directory for data in os.listdir(p)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory: str = f\"{os.getcwd()}/sparkAnaliysis/data/2020\"\n",
    "trip3: str = \"fhvhv_tripdata_2020-03.parquet\"\n",
    "trip4: str = \"fhvhv_tripdata_2020-04.parquet\"\n",
    "\n",
    "\n",
    "trip_data3 = spark.read.parquet(f\"file:///{directory}/{trip3}\")\n",
    "trip_data3.createOrReplaceTempView('month3_data')\n",
    "\n",
    "trip_data4 = spark.read.parquet(f\"file:///{directory}/{trip4}\")\n",
    "trip_data4.createOrReplaceTempView('month4_data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/19 17:58:02 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 809851 ms exceeds timeout 120000 ms\n",
      "23/01/19 17:58:02 WARN SparkContext: Killing executors is not supported by current scheduler.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "# select * from stocks join earnings on stocks.name = earnings.name\n",
    "# pickup_datetime pickup_datetime\n",
    "qs = \"\"\"\n",
    "select \n",
    "    trip3, trip4, count(*) as trips\n",
    "from\n",
    "    (select \n",
    "        split(month3_data.pickup_datetime, \" \")[0] as trip3, \n",
    "        split(month4_data.pickup_datetime, \" \")[0] as trip4\n",
    "    from \n",
    "        month3_data join month4_data on month3_data.hvfhs_license_num = month4_data.hvfhs_license_num)\n",
    "group by\n",
    "    trip3, trip4\n",
    "\"\"\"\n",
    "spark.sql(qs).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2516ec9dedd577fb6662378dc80c75bb748f265cb700a702aa389fbd4cb2ebee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
